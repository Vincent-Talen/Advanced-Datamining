{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eindopdracht Advanced Datamining\n",
    "\n",
    "## Studiejaar 2023-2024, 2e gelegenheid\n",
    "\n",
    "1. [Inleiding](#Inleiding)\n",
    "2. [Deel A](#Deel_A)\n",
    "3. [Deel B](#Deel_B)\n",
    "3. [Afsluiting](#Afsluiting)\n",
    "\n",
    "### <a id='Inleiding'>Inleiding</a>\n",
    "\n",
    "Dit is de *eindopdracht* behorende bij het vak *Advanced Datamining* (BFVH4DMN2) voor het *studiejaar 2023-2024 (2e gelegenheid)*. Op BlackBoard tref je eveneens een module `data.py` aan die diverse functies bevat die helpen bij het genereren en het visualiseren van de gebruikte datasets, en een bijbehorend data-bestand `EMNIST-mini.zip`.\n",
    "\n",
    "Gebruik de `model` module die je in werkcollegeopdrachten 1, 2, 3, 4, en 5 & 6 hebt gemaakt om de onderstaande opdrachten uit te voeren. Deze eindopdracht bestaat uit twee delen:\n",
    "\n",
    "- in **Deel A** worden een aantal cellen code gedraaid die als het goed is onmiddellijk zouden moeten werken met je model;\n",
    "\n",
    "- in **Deel B** wordt je gevraagd om je gemaakte model zelf toe te passen, maar hoef je je module als het goed is niet te wijzigen.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "**Waarschuwing:**\n",
    "\n",
    "De code in je module mag gebruik maken van alle functies uit de [Python Standard Library](https://docs.python.org/3/library/) (zoals `math`, `random`, `itertools`, enzovoorts); het is *niet* toegestaan om functies toe te passen uit overige modules (zoals `numpy`, `sklearn`, `tensorflow`, enzovoorts).\n",
    "\n",
    "</div>\n",
    "\n",
    "Eerst zetten we wat initialisatie op en importeren we naast de `data` en `model` modules enkele onderdelen van `pandas`, `numpy`, en `time`. Plaats de cursor in de cel hieronder en druk op Ctrl+Enter (of Shift+Enter om meteen naar de volgende cel te gaan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pandas import DataFrame, __version__\n",
    "print(f'Using pandas version {__version__}')\n",
    "\n",
    "from numpy import array, __version__\n",
    "print(f'Using numpy version {__version__}')\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "import model, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='Deel_A'>Deel A</a>\n",
    "\n",
    "Hieronder staan een aantal fragmenten code die je model *ongewijzigd* dient te kunnen uitvoeren. Voor verdere details omtrent deze gevraagde functionaliteiten, zie zonodig de werkcollege-opdrachten en/of de syllabus.\n",
    "\n",
    "#### Activatiefuncties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activations = [model.linear, model.tanh, model.softsign, model.sigmoid, model.softplus, model.relu, model.swish, model.sign]\n",
    "my_arguments =  [-1000, -1, 0, 1, 1000]\n",
    "my_table = [[φ(a) for a in my_arguments] for φ in my_activations]\n",
    "my_columns = [f'φ({a})' for a in my_arguments]\n",
    "my_rows = [φ.__name__ for φ in my_activations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.graph(my_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.graph([model.derivative(φ) for φ in my_activations if φ != model.sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(my_table, columns=my_columns).set_index(array(my_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lossfuncties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_losses = [model.mean_squared_error, model.mean_absolute_error, model.categorical_crossentropy, model.binary_crossentropy, model.hinge]\n",
    "my_arguments =  [0.01, 0.1, 0.5, 0.9, 0.99]\n",
    "my_table = [[L(a, 1.0) for a in my_arguments] for L in my_losses]\n",
    "my_columns = [f'L({a}; 1)' for a in my_arguments]\n",
    "my_rows = [L.__name__ for L in my_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.graph(my_losses, 1.0, xlim=(1e-2, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(my_table, columns=my_columns).set_index(array(my_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificatie: single-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.linear('nominal')\n",
    "my_model = model.Perceptron(dim=2)\n",
    "my_model.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificatie: support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.linear(outcome='nominal', noise=1.0)\n",
    "my_model = model.Neuron(dim=2, loss=model.hinge)\n",
    "my_model.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificatie: binomiale logistische regressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.linear(outcome='nominal', noise=1.0)\n",
    "ys = [(y + 1.0) / 2.0 for y in ys]   # Convert labels -1/+1 to 0/1\n",
    "my_model = model.Neuron(dim=2, activation=model.sigmoid, loss=model.binary_crossentropy)\n",
    "my_model.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificatie: multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.fractal(4)\n",
    "my_model = model.InputLayer(2) + \\\n",
    "           model.DenseLayer(20) + model.ActivationLayer(20, activation=model.tanh) + \\\n",
    "           model.DenseLayer(10) + model.ActivationLayer(10, activation=model.tanh) + \\\n",
    "           model.DenseLayer(4) + model.SoftmaxLayer(4) + \\\n",
    "           model.LossLayer(loss=model.categorical_crossentropy)\n",
    "my_model.fit(xs, ys, alpha=0.5, epochs=100, batch_size=20); my_model.fit(xs, ys, alpha=0.5, epochs=10)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressie: lineaire regressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.linear('numeric', noise=0.5)\n",
    "my_model = model.LinearRegression(dim=2)\n",
    "my_model.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressie: neuraal netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.concentric(noise=0.1)\n",
    "my_model = model.InputLayer(2) + \\\n",
    "           model.DenseLayer(20) + model.ActivationLayer(20, activation=model.tanh) + \\\n",
    "           model.DenseLayer(10) + model.ActivationLayer(10, activation=model.tanh) + \\\n",
    "           model.DenseLayer(1) + model.ActivationLayer(1, activation=model.linear) + \\\n",
    "           model.LossLayer(loss=model.mean_squared_error)\n",
    "my_model.fit(xs, ys, alpha=0.05, epochs=200, batch_size=10); my_model.fit(xs, ys, alpha=0.05, epochs=20)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='Deel_B'>Deel B</a>\n",
    "\n",
    "In dit deel ga je met een klassieke dataset aan de slag, de [Extended MNIST dataset](https://arxiv.org/pdf/1702.05373.pdf) die bestaat uit duizenden afbeeldingen van 28x28 pixels met handgeschreven cijfers en letters. Beschikbaar op BlackBoard is een bestand **EMNIST_mini.dat** (dat je dient te unzippen uit **EMNIST_mini.zip**) met een geminiaturiseerde versie met afbeeldingen van 12x12 pixels van alleen dat deel van de dataset dat betrekking heeft op de 26 verschillende hoofdletters. In totaal zijn er 52.000 instances beschikbaar, 2.000 van elke letter. De functie `data.emnist_mini()` kan gebruikt worden om een aantal instances op te vragen. Deze functie levert de attributen van de instances in de vorm van 144 pixel-intensiteiten tussen 0 en 1, en de klasselabels in de vorm van 26 getalwaarden met het juiste cijfer als een one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(data.emnist_mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiervan genereren we aanvankelijk om het simpel te houden slechts driehonderd instances elk voor de trainings-, validatie- en testdata. Onderzoek zelf de organisatie van deze data nader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 1: DATAGENERATIE\n",
    "xs, ys = data.emnist_mini('./EMNIST_mini.dat', num=900)\n",
    "trn_xs, trn_ys = xs[  0:300], ys[  0:300]\n",
    "val_xs, val_ys = xs[300:600], ys[300:600]\n",
    "tst_xs, tst_ys = xs[600:900], ys[600:900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder wordt een dummy model aangemaakt dat in dit geval bestaat uit een input, een hidden, en een outputlayer. Er is weliswaar vanalles aan te merken op dit overgesimplificeerde model, maar hanteer dit als een eerste uitgangspunt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 2: MODELDEFINITIE\n",
    "my_model = model.InputLayer(144, name='input') + \\\n",
    "           model.DenseLayer(26, name='hidden1') + \\\n",
    "           model.ActivationLayer(26, name='hidden2') + \\\n",
    "           model.LossLayer(name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens trainen en evalueren we dit model als volgt. Wederom zijn de gekozen parameters ongetwijfeld niet optimaal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 3: TRAINING\n",
    "my_history = my_model.fit(trn_xs, trn_ys, alpha=0.01, epochs=3, batch_size=1, validation_data=(val_xs, val_ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echter, hiermee kunnen we een validatiecurve construeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 4: VALIDATIECURVE\n",
    "data.curve(my_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om inzicht te krijgen in de prestaties van het model, worden hieronder twintig instances uit de testdata getoond met voor en na de pijl respectievelijk de juiste en de voorspelde klasselabels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 5: VISUALISATIE\n",
    "data.letters(tst_xs[:20], tst_ys[:20], model=my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berekenen we eens de gemiddelde loss op alle testdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 6: EVALUATIE\n",
    "print(f'Loss: {my_model.evaluate(tst_xs, tst_ys)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit getal zegt misschien nog niet zoveel. Daarom bekijken we een grafische weergave van de [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) die weergeeft welke voorspelde klasselabels op de $x$-as aan alle echte klasselabels op de $y$-as worden toegekend (let op de logaritmische kleurschaal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 7: CONFUSIONMATRIX\n",
    "data.confusion(tst_xs, tst_ys, model=my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoewel er best wat fouten worden gemaakt liggen er toch behoorlijk wat juist geclassificeerde instances op de diagonaal. Daarnaast, een aantal van de meest gemaakte fouten betreft letters die ook wel enigszins op elkaar lijken. Dit overdreven simpele model bereikt - afhankelijk van de willekeurig gekozen instances en initialisatiewaarden - een nauwkeurigheid van rond de 25%, wat wil zeggen dat ongeveer een vierde van de letters correct wordt herkend. Dit is nog niet indrukwekkend goed, maar gezien de eenvoudige opbouw van het model al best verrassend en in elk geval ruim boven de 1/26 ≈ 4% nauwkeurigheid die je mag verwachten op grond van kans alleen.\n",
    "\n",
    "***\n",
    "\n",
    "Pas nu hieronder eens het bovenstaande model aan tot een neuraal netwerk dat deze afbeeldingen redelijk betrouwbaar kan classificeren. Kies zelf een geschikte opzet van het model en bepaal door te experimenteren geschikte waarden voor de diverse parameters. Voer dezelfde zeven stappen uit als hierboven, maar dan met een effectiever en beter geoptimaliseerd model.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Opdracht:**\n",
    "\n",
    "Gebruik tenminste ergens in je model de *exponential linear sigmoid squashing* (ELiSH) of de *hard exponential linear sigmoid squashing* (HardELiSH) activatiefunctie die door Mina Basirat &amp; Peter M. Roth als optimaal werden gerapporteerd (in \"The Quest for the Golden Activation Function\", 2018). Zoek hier zonodig informatie over op en implementeer deze in je module; houd daarbij rekening met overflow.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verander deze cel niet\n",
    "starttime = perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 1: DATAGENERATIE\n",
    "# Voer hier je eigen code uit ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 2: MODELDEFINITIE\n",
    "# Voer hier je eigen code uit ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 3: TRAINING\n",
    "# Voer hier je eigen code uit ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 4: VALIDATIECURVE\n",
    "# Voer hier je eigen code uit ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 5: VISUALISATIE\n",
    "# Voer hier je eigen code uit ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 6: EVALUATIE\n",
    "# Voer hier je eigen code uit ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# STAP 7: CONFUSIONMATRIX\n",
    "# Voer hier je eigen code uit ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verander deze cel niet\n",
    "print(f'Verstreken tijd: {(perf_counter() - starttime) / 60.0:.1f} minuten.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "Voer achtereenvolgens de onderstaande ontwikkelstappen uit.\n",
    "\n",
    "</div>\n",
    "\n",
    "* creëer eerst een model met meerdere hidden layers waarin gezamenlijk in de ordegrootte van ruim een honderdtal neuronen verwerkt zijn;\n",
    "\n",
    "* stel dan de invoer- & uitvoerlagen en activatie- & loss-functies zo in dat het model geschikt is voor deze classificatie-taak;\n",
    "\n",
    "* begin met een datasetje van zeer beperkte grootte zodat het model in niet meer dan ongeveer een minuut over een klein aantal epochs te trainen is;\n",
    "\n",
    "* kies een grootte voor de mini-batches die naar jouw inschatting net genoeg is om een enigszins representatieve steekproef van de data te vormen;\n",
    "\n",
    "* probeer aanvankelijk een relatief grote learning rate uit en stel deze bij naar beneden zolang het model niet in staat is een dalende validatie-curve te tonen;\n",
    "\n",
    "* start met enkele epochs en voer dit op totdat de validatiecurve aangeeft dat het model redelijk getraind raakt (de trainingstijd neemt hierbij evenredig toe);\n",
    "\n",
    "* vergroot dan geleidelijk de grootte van de datasets (waarbij het nodige aantal epochs afneemt omdat er per epoch meer mini-batches getraind worden);\n",
    "\n",
    "* je mag alle 52.000 instances uiteindelijk gebruiken, maar dat is niet verplicht;\n",
    "\n",
    "* speel met de bovenstaande procedure tot je een model hebt gevonden dat in een werkbare tijd toch naar tevredenheid convergeert.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Opmerking:**\n",
    "\n",
    "Ter indicatie, een deugdelijk model is in zijn uiteindelijke vorm op een typische hedendaagse CPU na enkele tientallen minuten training (eis: maximaal 1 uur) in staat om ruim 80% (eis: minimaal 70%) accuracy te behalen zonder daarbij zichtbaar te overfitten.\n",
    "\n",
    "</div>\n",
    "\n",
    "### <a id='Afsluiting'>Afsluiting</a>\n",
    "\n",
    "Als je klaar bent, lever dan je uitwerkingen als volgt in:\n",
    "\n",
    "1. Sla je model vanuit je code-editor op als **model.py**;\n",
    "\n",
    "2. Evalueer dit notebook door vanuit het menu *Kernel > Restart & Run All* te kiezen;\n",
    "\n",
    "3. Controleer dat alle uitvoer correct en volledig wordt geproduceerd;\n",
    "\n",
    "4. Exporteer dit notebook als **Eindopdracht_v2324.2.html** vanuit het menu *File > Download as > HTML (.html)*;\n",
    "\n",
    "5. Verwijder vervolgens de uitvoer in dit notebook via het menu *Cell > All Output > Clear*;\n",
    "\n",
    "6. Sla dit notebook op als **Eindopdracht_v2324.2.ipynb** middels het menu *File > Save and Checkpoint*;\n",
    "\n",
    "7. Comprimeer alledrie de hierboven genoemde bestanden in één bestand **Eindopdracht_v2324.2.zip**;\n",
    "\n",
    "8. Lever je zip-bestand uiterlijk **zondag 23 juni 2024** (23:59) in op BlackBoard;\n",
    "\n",
    "9. E-mail de docent met je voorkeurstijdstippen voor het mondelinge tentamen.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "**Waarschuwing:**\n",
    "\n",
    "Verifieer dat je het juiste bestand uploadt, want eenmaal ingestuurd werk geldt als definitief!\n",
    "\n",
    "</div>\n",
    "\n",
    "Succes!\n",
    "\n",
    "***\n",
    "\n",
    "<small>&copy; 2024, Dave R.M. Langers, [d.r.m.langers@pl.hanze.nl](mailto:d.r.m.langers@pl.hanze.nl)</small>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
